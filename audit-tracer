"""
Core AuditTracer implementation for LLM interaction auditing.
This module provides the main interface for cryptographic auditing of LLM agent
interactions, with support for compliance standards and tamper-proof logging.

Author: David Hassoun
Copyright (c) 2025 David Hassoun
"""
import time
import json
import uuid
import sqlite3
import threading
import hashlib
import hmac
import logging
import secrets
from typing import Dict, Any, Optional, List, Tuple, Union
from pathlib import Path
from contextlib import contextmanager


# Logging configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CryptoEngine:
    """Cryptographic engine for event integrity verification."""
    
    def __init__(self, crypto_key: Optional[str] = None):
        self.key = crypto_key or self._generate_key()
    
    def _generate_key(self) -> str:
        """Generate a secure cryptographic key."""
        return secrets.token_hex(32)  # 256 bits of security
    
    def hash_event(self, event: Dict[str, Any]) -> str:
        """Generate HMAC-SHA256 hash for an event."""
        try:
            event_str = json.dumps(event, sort_keys=True, ensure_ascii=False)
            return hmac.new(
                self.key.encode('utf-8'),
                event_str.encode('utf-8'),
                hashlib.sha256
            ).hexdigest()
        except (TypeError, ValueError) as e:
            logger.error(f"Error hashing event: {e}")
            raise
    
    def calculate_merkle_root(self, hashes: List[str]) -> str:
        """Calculate Merkle root for a list of hashes."""
        if not hashes:
            return ""
        if len(hashes) == 1:
            return hashes[0]
        
        # Robust Merkle tree implementation
        current_level = hashes[:]
        while len(current_level) > 1:
            next_level = []
            for i in range(0, len(current_level), 2):
                if i + 1 < len(current_level):
                    combined = current_level[i] + current_level[i + 1]
                else:
                    # For odd numbers, duplicate the last hash
                    combined = current_level[i] + current_level[i]
                next_level.append(hashlib.sha256(combined.encode('utf-8')).hexdigest())
            current_level = next_level
        
        return current_level[0]


class ComplianceManager:
    """Compliance manager for different regulatory standards."""
    
    SUPPORTED_MODES = {
        "medical": {
            "standard": "FDA 21 CFR Part 11",
            "min_retention_years": 7,
            "requires_signatures": True
        },
        "financial": {
            "standard": "SOX 404",
            "min_retention_years": 7,
            "requires_signatures": True
        },
        "general": {
            "standard": "General Audit",
            "min_retention_years": 3,
            "requires_signatures": False
        }
    }
    
    def __init__(self, compliance_mode: Optional[str] = None):
        self.compliance_mode = compliance_mode or "general"
        
        if self.compliance_mode not in self.SUPPORTED_MODES:
            raise ValueError(
                f"Unsupported compliance mode: {self.compliance_mode}. "
                f"Supported modes: {list(self.SUPPORTED_MODES.keys())}"
            )
        
        self.config = self.SUPPORTED_MODES[self.compliance_mode]
    
    def get_interaction_metadata(self) -> Dict[str, Any]:
        """Return compliance metadata for an interaction."""
        return {
            "compliance_mode": self.compliance_mode,
            "compliance_standard": self.config["standard"],
            "timestamp": time.time(),
            "retention_required": self.config["min_retention_years"],
            "requires_signatures": self.config["requires_signatures"]
        }
    
    def validate_retention_period(self, retention_years: int) -> bool:
        """Validate that retention period meets requirements."""
        return retention_years >= self.config["min_retention_years"]
    
    def generate_report_metadata(self, events: List[Dict], retention_years: int) -> Dict[str, Any]:
        """Generate metadata for a compliance report."""
        if not self.validate_retention_period(retention_years):
            logger.warning(
                f"Retention period {retention_years} years is below minimum "
                f"requirement of {self.config['min_retention_years']} years for {self.compliance_mode}"
            )
        
        llm_interactions = [e for e in events if e.get("event_type") == "llm_interaction"]
        
        return {
            "compliance_standard": self.config["standard"],
            "retention_period_years": retention_years,
            "meets_retention_requirements": self.validate_retention_period(retention_years),
            "total_interactions": len(llm_interactions),
            "total_events": len(events),
            "audit_period": {
                "start": min((e.get("timestamp", 0) for e in events), default=0),
                "end": max((e.get("timestamp", 0) for e in events), default=0)
            }
        }


class ReplayEngine:
    """Replay engine for session analysis."""
    
    def __init__(self, events: List[Dict], crypto_engine: CryptoEngine):
        self.events = sorted(events, key=lambda x: x.get("timestamp", 0))
        self.crypto_engine = crypto_engine
    
    def replay_session(self) -> Dict[str, Any]:
        """Replay a complete session."""
        llm_interactions = [e for e in self.events if e.get("event_type") == "llm_interaction"]
        
        return {
            "total_events": len(self.events),
            "session_duration": self._calculate_duration(),
            "interaction_count": len(llm_interactions),
            "first_event": self.events[0]["timestamp"] if self.events else None,
            "last_event": self.events[-1]["timestamp"] if self.events else None,
            "event_types": self._get_event_type_distribution()
        }
    
    def _calculate_duration(self) -> float:
        """Calculate session duration."""
        if len(self.events) < 2:
            return 0.0
        return self.events[-1].get("timestamp", 0) - self.events[0].get("timestamp", 0)
    
    def _get_event_type_distribution(self) -> Dict[str, int]:
        """Return distribution of event types."""
        distribution = {}
        for event in self.events:
            event_type = event.get("event_type", "unknown")
            distribution[event_type] = distribution.get(event_type, 0) + 1
        return distribution


class AuditTracer:
    """Main interface for cryptographic auditing of LLM interactions."""
    
    def __init__(
        self,
        session_id: Optional[str] = None,
        storage_path: str = "./audit_logs",
        compliance_mode: Optional[str] = None,
        retention_years: int = 3,
        crypto_key: Optional[str] = None
    ):
        """
        Initialize AuditTracer with compliance configuration.
        
        Args:
            session_id: Unique session identifier
            storage_path: Directory for audit log storage
            compliance_mode: "medical", "financial", or "general"
            retention_years: Data retention period
            crypto_key: Custom cryptographic key (auto-generated if None)
        """
        self.session_id = session_id or str(uuid.uuid4())
        self.storage_path = Path(storage_path)
        self.retention_years = retention_years
        
        # Create storage directory
        try:
            self.storage_path.mkdir(parents=True, exist_ok=True)
        except OSError as e:
            logger.error(f"Cannot create storage directory {self.storage_path}: {e}")
            raise
        
        # Initialize main components
        try:
            self.compliance_manager = ComplianceManager(compliance_mode)
            if not self.compliance_manager.validate_retention_period(retention_years):
                logger.warning(
                    f"Retention period {retention_years} years may not meet "
                    f"compliance requirements for {compliance_mode}"
                )
            
            self.crypto_engine = CryptoEngine(crypto_key=crypto_key)
        except Exception as e:
            logger.error(f"Error initializing components: {e}")
            raise
        
        # Database connection
        self.db_path = self.storage_path / f"{self.session_id}.db"
        self._init_database()
        
        # Thread safety
        self._lock = threading.RLock()
        self._active_session = False

    def _init_database(self):
        """Initialize SQLite database for audit storage."""
        try:
            with sqlite3.connect(str(self.db_path)) as conn:
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS audit_events (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        event_id TEXT UNIQUE NOT NULL,
                        session_id TEXT NOT NULL,
                        timestamp REAL NOT NULL,
                        event_type TEXT NOT NULL,
                        data TEXT NOT NULL,
                        hash TEXT NOT NULL,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # Index for performance improvement
                conn.execute('''
                    CREATE INDEX IF NOT EXISTS idx_session_timestamp 
                    ON audit_events(session_id, timestamp)
                ''')
                
                conn.commit()
            logger.info(f"Database initialized: {self.db_path}")
        except sqlite3.Error as e:
            logger.error(f"Error initializing database: {e}")
            raise

    def wrap_client(self, client):
        """Wrap LLM client to enable automatic interaction tracing."""
        if hasattr(client, 'chat') and hasattr(client.chat, 'completions'):
            return OpenAIInterceptor(client, self)
        else:
            raise ValueError(f"Unsupported client type: {type(client)}")

    @contextmanager
    def audit_session(self):
        """Context manager for audit session lifecycle."""
        self._active_session = True
        start_time = time.time()
        
        # Session start event
        self.log_event("session_start", {
            "compliance_mode": self.compliance_manager.compliance_mode,
            "retention_years": self.retention_years,
            "framework_author": "David Hassoun"
        })
        
        try:
            yield self
        except Exception as e:
            # Log exception
            self.log_event("session_exception", {
                "exception_type": type(e).__name__,
                "exception_message": str(e)
            })
            raise
        finally:
            # Session end event
            duration = time.time() - start_time
            self.log_event("session_end", {
                "duration_seconds": duration,
                "total_events": len(self._get_all_events())
            })
            self._active_session = False

    def log_event(self, event_type: str, data: Dict[str, Any]) -> str:
        """Log an event with cryptographic hash for integrity verification."""
        if not isinstance(event_type, str) or not event_type.strip():
            raise ValueError("event_type must be a non-empty string")
        
        if not isinstance(data, dict):
            raise ValueError("data must be a dictionary")
        
        with self._lock:
            event = {
                "event_id": str(uuid.uuid4()),
                "session_id": self.session_id,
                "timestamp": time.time(),
                "event_type": event_type.strip(),
                "data": data
            }
            
            try:
                # Generate cryptographic hash
                event_hash = self.crypto_engine.hash_event(event)
                event["hash"] = event_hash
                
                # Store in database
                with sqlite3.connect(str(self.db_path)) as conn:
                    conn.execute('''
                        INSERT INTO audit_events
                        (event_id, session_id, timestamp, event_type, data, hash)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (
                        event["event_id"],
                        event["session_id"],
                        event["timestamp"],
                        event["event_type"],
                        json.dumps(event["data"]),
                        event["hash"]
                    ))
                    conn.commit()
                
                logger.debug(f"Event logged: {event['event_id']}")
                return event["event_id"]
                
            except (sqlite3.Error, json.JSONEncodeError) as e:
                logger.error(f"Error logging event: {e}")
                raise

    def log_llm_interaction(
        self,
        provider: str,
        model: str,
        messages: List[Dict],
        response: Union[Dict, Any],
        metadata: Optional[Dict] = None
    ) -> str:
        """Log LLM API interaction with complete context."""
        # Parameter validation
        if not provider or not isinstance(provider, str):
            raise ValueError("provider must be a non-empty string")
        if not model or not isinstance(model, str):
            raise ValueError("model must be a non-empty string")
        if not isinstance(messages, list):
            raise ValueError("messages must be a list")
        
        # Safe response conversion
        try:
            if hasattr(response, 'model_dump'):
                response_dict = response.model_dump()
            elif hasattr(response, 'dict'):
                response_dict = response.dict()
            elif hasattr(response, '__dict__'):
                response_dict = {
                    k: v for k, v in response.__dict__.items()
                    if not k.startswith('_')
                }
            else:
                response_dict = dict(response) if response else {}
        except Exception as e:
            logger.warning(f"Could not serialize response: {e}")
            response_dict = {"serialization_error": str(e)}
        
        interaction_data = {
            "provider": provider.strip(),
            "model": model.strip(),
            "messages": messages,
            "response": response_dict,
            "token_usage": response_dict.get("usage", {}),
            "latency_ms": metadata.get("latency_ms", 0) if metadata else 0,
            "compliance_metadata": self.compliance_manager.get_interaction_metadata()
        }
        
        return self.log_event("llm_interaction", interaction_data)

    def export_compliance_report(self) -> Dict[str, Any]:
        """Export comprehensive compliance report for audit."""
        try:
            events = self._get_all_events()
            
            # Cryptographic integrity verification
            integrity_valid, verification_details = self.verify_integrity()
            
            # Generate compliance-specific metadata
            compliance_metadata = self.compliance_manager.generate_report_metadata(
                events, self.retention_years
            )
            
            return {
                "session_id": self.session_id,
                "export_timestamp": time.time(),
                "total_events": len(events),
                "integrity_verified": integrity_valid,
                "verification_details": verification_details,
                "compliance_metadata": compliance_metadata,
                "events": events,
                "framework_info": {
                    "name": "LLMAuditTrail",
                    "version": "0.1.0",
                    "author": "David Hassoun"
                }
            }
        except Exception as e:
            logger.error(f"Error exporting compliance report: {e}")
            raise

    def verify_integrity(self) -> Tuple[bool, Dict[str, Any]]:
        """Verify cryptographic integrity of complete audit trail."""
        try:
            events = self._get_all_events()
            if not events:
                return True, {"message": "No events to verify", "total_events": 0}
            
            verification_results = []
            invalid_count = 0
            
            for event in events:
                try:
                    # Reconstruct event without hash for verification
                    event_data = {
                        "event_id": event["event_id"],
                        "session_id": event["session_id"],
                        "timestamp": event["timestamp"],
                        "event_type": event["event_type"],
                        "data": json.loads(event["data"]) if isinstance(event["data"], str) else event["data"]
                    }
                    
                    expected_hash = self.crypto_engine.hash_event(event_data)
                    is_valid = hmac.compare_digest(event["hash"], expected_hash)
                    
                    if not is_valid:
                        invalid_count += 1
                    
                    verification_results.append({
                        "event_id": event["event_id"],
                        "hash_valid": is_valid,
                        "timestamp": event["timestamp"]
                    })
                    
                except (json.JSONDecodeError, KeyError) as e:
                    logger.error(f"Error verifying event {event.get('event_id', 'unknown')}: {e}")
                    verification_results.append({
                        "event_id": event.get("event_id", "unknown"),
                        "hash_valid": False,
                        "error": str(e)
                    })
                    invalid_count += 1
            
            all_valid = invalid_count == 0
            
            # Calculate Merkle root for additional verification
            event_hashes = [event["hash"] for event in events]
            merkle_root = self.crypto_engine.calculate_merkle_root(event_hashes)
            
            return all_valid, {
                "total_events": len(events),
                "valid_events": len(events) - invalid_count,
                "invalid_events": invalid_count,
                "verification_results": verification_results,
                "merkle_root": merkle_root,
                "crypto_algorithm": "HMAC-SHA256"
            }
        except Exception as e:
            logger.error(f"Error verifying integrity: {e}")
            return False, {"error": str(e)}

    def create_replay_engine(self, target_session_id: Optional[str] = None) -> ReplayEngine:
        """Create replay engine for session analysis."""
        session_id = target_session_id or self.session_id
        events = self._get_all_events(session_id)
        return ReplayEngine(events, self.crypto_engine)

    def _get_all_events(self, session_id: Optional[str] = None) -> List[Dict]:
        """Retrieve all events for specified session."""
        target_session = session_id or self.session_id
        try:
            with sqlite3.connect(str(self.db_path)) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.execute(
                    'SELECT * FROM audit_events WHERE session_id = ? ORDER BY timestamp',
                    (target_session,)
                )
                events = [dict(row) for row in cursor.fetchall()]
            return events
        except sqlite3.Error as e:
            logger.error(f"Error retrieving events: {e}")
            return []


class OpenAIInterceptor:
    """Transparent interceptor for OpenAI API client calls."""
    
    def __init__(self, client, tracer: AuditTracer):
        self._client = client
        self._tracer = tracer
        
        # Preserve original client interface
        for attr in dir(client):
            if not attr.startswith('_') and attr not in ['chat']:
                try:
                    setattr(self, attr, getattr(client, attr))
                except AttributeError:
                    pass
        
        # Wrap chat completions
        self.chat = ChatCompletionsWrapper(client.chat, tracer)


class ChatCompletionsWrapper:
    """Wrapper for OpenAI chat completions with audit logging."""
    
    def __init__(self, chat, tracer):
        self._chat = chat
        self._tracer = tracer
        
        # Preserve original interface
        for attr in dir(chat):
            if not attr.startswith('_') and attr not in ['completions']:
                try:
                    setattr(self, attr, getattr(chat, attr))
                except AttributeError:
                    pass
        
        self.completions = CompletionsWrapper(chat.completions, tracer)


class CompletionsWrapper:
    """Wrapper for OpenAI completions with complete audit trail."""
    
    def __init__(self, completions, tracer):
        self._completions = completions
        self._tracer = tracer

    def create(self, **kwargs):
        """Intercept and log completion creation."""
        start_time = time.time()
        
        try:
            # Original API call
            response = self._completions.create(**kwargs)
            
            # Calculate latency
            latency_ms = (time.time() - start_time) * 1000
            
            # Log interaction
            self._tracer.log_llm_interaction(
                provider="openai",
                model=kwargs.get("model", "unknown"),
                messages=kwargs.get("messages", []),
                response=response,
                metadata={"latency_ms": latency_ms}
            )
            
            return response
            
        except Exception as e:
            # Log error
            self._tracer.log_event("llm_error", {
                "provider": "openai",
                "model": kwargs.get("model", "unknown"),
                "error": str(e),
                "error_type": type(e).__name__,
                "latency_ms": (time.time() - start_time) * 1000
            })
            raise


# Example usage and testing
if __name__ == "__main__":
    # Example of how to use the AuditTracer
    tracer = AuditTracer(
        compliance_mode="medical",
        retention_years=7,
        storage_path="./medical_audit_logs"
    )
    
    with tracer.audit_session():
        # Log some example events
        tracer.log_event("user_login", {"user_id": "user123", "ip": "192.168.1.1"})
        
        # Simulate LLM interaction
        tracer.log_llm_interaction(
            provider="openai",
            model="gpt-4",
            messages=[{"role": "user", "content": "Hello, world!"}],
            response={"choices": [{"message": {"content": "Hello! How can I help?"}}]},
            metadata={"latency_ms": 1250}
        )
    
    # Export compliance report
    report = tracer.export_compliance_report()
    print(f"Audit complete. Total events: {report['total_events']}")
    print(f"Integrity verified: {report['integrity_verified']}")
